{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d68209-7c8b-4337-949b-7a936a02dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark\n",
    "# Import necessary modules\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import pyspark.sql.types as tp\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DiabetesPredictionPipeline\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "####### Define the schema for the data\n",
    "my_schema = tp.StructType([\n",
    "    tp.StructField(name='Pregnancies', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='Glucose', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='BloodPressure', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='SkinThickness', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='Insulin', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='BMI', dataType=tp.DoubleType(), nullable=True),\n",
    "    tp.StructField(name='DiabetesPedigreeFunction', dataType=tp.DoubleType(), nullable=True),\n",
    "    tp.StructField(name='Age', dataType=tp.IntegerType(), nullable=True),\n",
    "    tp.StructField(name='Outcome', dataType=tp.IntegerType(), nullable=True)\n",
    "])\n",
    "\n",
    "####### Read the data with the defined schema\n",
    "my_data = spark.read.csv('diabetes.csv', schema=my_schema, header=True)\n",
    "\n",
    "# Print the schema to verify structure\n",
    "my_data.printSchema()\n",
    "\n",
    "# Print the first 5 rows for quick inspection\n",
    "my_data.show(5, truncate=False)\n",
    "\n",
    "####### Replace zeros with nulls in specific columns\n",
    "cols_to_check = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "for col in cols_to_check:\n",
    "    my_data = my_data.withColumn(col, when(my_data[col] == 0, None).otherwise(my_data[col]))\n",
    "\n",
    "# Define stages for the pipeline\n",
    "imputer = Imputer(\n",
    "    inputCols=cols_to_check,\n",
    "    outputCols=[f\"{c}_imputed\" for c in cols_to_check]\n",
    ").setStrategy(\"median\")\n",
    "\n",
    "######\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['Pregnancies', 'Glucose_imputed', 'BloodPressure_imputed',\n",
    "               'SkinThickness_imputed', 'Insulin_imputed', 'BMI_imputed',\n",
    "               'DiabetesPedigreeFunction', 'Age'],\n",
    "    outputCol='features'\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='Outcome', maxIter=10)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=[imputer, assembler, lr])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "xtrain, xtest = my_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline_model = pipeline.fit(xtrain)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = pipeline_model.transform(xtest)\n",
    "\n",
    "# Show predictions (first 5 rows) to verify output\n",
    "predictions.select(\"features\", \"Outcome\", \"prediction\").show(5, truncate=False)\n",
    "\n",
    "####### Evaluate the model using AUC\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Outcome\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "print(f\"Model AUC: {auc:.4f}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = predictions.filter(predictions[\"Outcome\"] == predictions[\"prediction\"]).count()\n",
    "total = predictions.count()\n",
    "accuracy = correct / total\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec88e8b-544f-4283-b3cd-d7dd73b9a7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887f2ae-ae2c-4b65-bd81-1d785cec20f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4453ba-ed58-4ca1-878f-e460c8c13615",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "data = [(\"James\",\"Smith\",\"IND\",\"MH\"),(\"Michael\",\"Rose\",\"IND\",\"MP\"), \\\n",
    "    (\"Robert\",\"Williams\",\"IND\",\"UP\"),(\"Maria\",\"Jones\",\"IND\",\"TN\") \\\n",
    "  ]\n",
    "columns=[\"firstname\",\"lastname\",\"country\",\"state\"]\n",
    "df=spark.createDataFrame(data=data,schema=columns)\n",
    "df.show()\n",
    "print(df.collect())\n",
    "\n",
    "\n",
    "states1=df.rdd.map(lambda x: x[3]).collect()\n",
    "print(states1)\n",
    "from collections import OrderedDict\n",
    "res = list(OrderedDict.fromkeys(states1))\n",
    "print(res)\n",
    "\n",
    "\n",
    "\n",
    "#Example 2\n",
    "states2=df.rdd.map(lambda x: x.state).collect()\n",
    "print(states2)\n",
    "\n",
    "states3=df.select(df.state).collect()\n",
    "print(states3)\n",
    "\n",
    "states4=df.select(df.state).rdd.flatMap(lambda x: x).collect()\n",
    "print(states4)\n",
    "\n",
    "states5=df.select(df.state).toPandas()['state']\n",
    "states6=list(states5)\n",
    "print(states6)\n",
    "\n",
    "pandDF=df.select(df.state,df.firstname).toPandas()\n",
    "print(list(pandDF['state']))\n",
    "print(list(pandDF['firstname']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
